# Day 12. Classification metrics
## Today's objective
Understand and apply classification metrics to evaluate machine learning models beyond just accuracy. Learn when and why to use precision, recall, F1-score, and confusion matrices.

## Explanation 

When working with classification tasks (spam vs. not spam, healthy vs. sick, etc.), accuracy alone can be misleading, especially with imbalanced datasets.

Key metrics:

- Accuracy: Proportion of correct predictions.
- Precision: Out of all predicted positives, how many are correct? (Good for avoiding false positives).
- Recall (Sensitivity): Out of all actual positives, how many did we catch? (Good for avoiding false negatives).
- F1-score: Harmonic mean of precision and recall, balances both.
- Confusion Matrix: Table summarizing true positives, false positives, true negatives, and false negatives.
- ROC Curve & AUC: Show tradeoff between sensitivity and specificity across thresholds.

